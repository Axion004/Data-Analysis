{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Winning Jeopardy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://s.abcnews.com/images/Entertainment/GTY_ken_jennings_jeopardy_jt_141126_16x9_608.jpg)\n",
    "\n",
    "Image Source: Ken Jennings poses in this handout photo.\n",
    "Jeopardy Productions via Getty Images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "---\n",
    "- [Introduction](#Introduction)\n",
    "- [Data Preparation](#Data-Preparation)\n",
    "- [Setting the environment](#Setting-the-environment)\n",
    "- [Reading and inspecting the data](#Reading-and-inspecting-the-data)\n",
    "- [Data Cleaning](#Data-Cleaning)\n",
    "- [Removing white spaces from column names](#Removing-white-spaces-from-column-names)\n",
    "- [Normalizing Question and Answer Columns](#Normalizing-Question-and-Answer-Columns)\n",
    "- [Normalizing the Value and Air Date Columns](#Normalizing-the-Value-and-Air-Date-Columns)\n",
    "- [Data Analysis](#Data-Analysis)\n",
    "- [How often the answer can be used for a question](#How-often-the-answer-can-be-used-for-a-question)\n",
    "- [How often questions are repeated](#How-often-questions-are-repeated)\n",
    "- [Low Value vs High Value Questions](#Low-Value-vs-High-Value-Questions)\n",
    "- [Statistical Analysis](#Statistical-Analysis)\n",
    "- [Conclusions](#Conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. It's been running for many years, and is a major force in popular culture. In this project, we'll work with a dataset of Jeopardy questions to figure out some patterns in the questions that could help us win.\n",
    "\n",
    "The dataset contains 20,000 rows from the beginning of a full dataset of Jeopardy questions, which can be downloaded [here](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/). Each row in the dataset represents a single question on a single episode of Jeopardy. Here are explanations of each column:\n",
    "\n",
    "- Show Number - the Jeopardy episode number\n",
    "- Air Date - the date the episode aired\n",
    "- Round - the round of Jeopardy\n",
    "- Category - the category of the question\n",
    "- Value - the number of dollars the correct answer is worth\n",
    "- Question - the text of the question\n",
    "- Answer - the text of the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Reading and inspecting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe: (19999, 7)\n",
      "Columns of the dataframe: Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
      "       ' Question', ' Answer'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 7 columns):\n",
      "Show Number    19999 non-null int64\n",
      " Air Date      19999 non-null datetime64[ns]\n",
      " Round         19999 non-null object\n",
      " Category      19999 non-null object\n",
      " Value         19999 non-null object\n",
      " Question      19999 non-null object\n",
      " Answer        19999 non-null object\n",
      "dtypes: datetime64[ns](1), int64(1), object(5)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "   Show Number   Air Date      Round                         Category  Value  \\\n",
      "0         4680 2004-12-31  Jeopardy!                          HISTORY   $200   \n",
      "1         4680 2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
      "2         4680 2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
      "3         4680 2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
      "4         4680 2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
      "\n",
      "                                            Question      Answer  \n",
      "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
      "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
      "2  The city of Yuma in this state has a record av...     Arizona  \n",
      "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
      "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  \n"
     ]
    }
   ],
   "source": [
    "# Read the csv file, parsing dates from the \"Air Date\" column\n",
    "jeopardy = pd.read_csv(\"jeopardy.csv\", parse_dates = [\" Air Date\"])\n",
    "\n",
    "# Display dataframe information\n",
    "print(\"Shape of the dataframe:\", jeopardy.shape)\n",
    "print(\"Columns of the dataframe:\", jeopardy.columns)\n",
    "print(jeopardy.info())\n",
    "print(jeopardy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing white spaces from column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of the dataframe: Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
      "       ' Question', ' Answer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Original columns with white space\n",
    "print(\"Columns of the dataframe:\", jeopardy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of the dataframe: Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
      "       'Answer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Remove white spaces from column names\n",
    "jeopardy.columns = ['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question', 'Answer']\n",
    "\n",
    "print(\"Columns of the dataframe:\", jeopardy.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Question and Answer Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll continue by converting `Question` and `Answer` columns to lowercase. We will also remove all punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Show Number   Air Date      Round                         Category Value  \\\n",
      "0         4680 2004-12-31  Jeopardy!                          HISTORY  $200   \n",
      "1         4680 2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
      "2         4680 2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
      "3         4680 2004-12-31  Jeopardy!                 THE COMPANY LINE  $200   \n",
      "4         4680 2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES  $200   \n",
      "\n",
      "                                            Question      Answer  \\\n",
      "0  For the last 8 years of his life, Galileo was ...  Copernicus   \n",
      "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe   \n",
      "2  The city of Yuma in this state has a record av...     Arizona   \n",
      "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's   \n",
      "4  Signer of the Dec. of Indep., framer of the Co...  John Adams   \n",
      "\n",
      "                                      clean_question clean_answer  \n",
      "0  for the last 8 years of his life galileo was u...   copernicus  \n",
      "1  no 2 1912 olympian football star at carlisle i...   jim thorpe  \n",
      "2  the city of yuma in this state has a record av...      arizona  \n",
      "3  in 1963 live on the art linkletter show this c...    mcdonalds  \n",
      "4  signer of the dec of indep framer of the const...   john adams  \n"
     ]
    }
   ],
   "source": [
    "def normalize(string):\n",
    "    \"\"\"\n",
    "    Takes a string as an input. Transforms the string by removing the punctuation and \n",
    "    converting to lowercase.\n",
    "    \n",
    "    Args:\n",
    "        string: String to be normalized\n",
    "    \n",
    "    Returns:\n",
    "        normalized_string: Lowcase string without punctuation\n",
    "    \"\"\"\n",
    "    \n",
    "    lower_string = str(string).lower()\n",
    "    normalized_string = re.sub(r\"[^\\w\\s]\", \"\", lower_string) # ^ means negation. So [^\\w\\s] will match a character which\n",
    "                                                             # does not belong to either the word or the whitespace group\n",
    "    return normalized_string\n",
    "\n",
    "# Apply the normalization function to the \"Question\" and \"Answer\" columns\n",
    "jeopardy[\"clean_question\"] = jeopardy[\"Question\"].apply(normalize)\n",
    "jeopardy[\"clean_answer\"] = jeopardy[\"Answer\"].apply(normalize)\n",
    "\n",
    "# Display results\n",
    "print(jeopardy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the Value and Air Date Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now convert the `Value` column to a numeric column by removing the dollar sign from the beginning of each value. We'll also convert the `Air Date` column to a datetime column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Show Number   Air Date      Round                         Category Value  \\\n",
      "0         4680 2004-12-31  Jeopardy!                          HISTORY  $200   \n",
      "1         4680 2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
      "2         4680 2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
      "3         4680 2004-12-31  Jeopardy!                 THE COMPANY LINE  $200   \n",
      "4         4680 2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES  $200   \n",
      "\n",
      "                                            Question      Answer  \\\n",
      "0  For the last 8 years of his life, Galileo was ...  Copernicus   \n",
      "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe   \n",
      "2  The city of Yuma in this state has a record av...     Arizona   \n",
      "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's   \n",
      "4  Signer of the Dec. of Indep., framer of the Co...  John Adams   \n",
      "\n",
      "                                      clean_question clean_answer  clean_value  \n",
      "0  for the last 8 years of his life galileo was u...   copernicus          200  \n",
      "1  no 2 1912 olympian football star at carlisle i...   jim thorpe          200  \n",
      "2  the city of yuma in this state has a record av...      arizona          200  \n",
      "3  in 1963 live on the art linkletter show this c...    mcdonalds          200  \n",
      "4  signer of the dec of indep framer of the const...   john adams          200  \n"
     ]
    }
   ],
   "source": [
    "def norm_value(value):\n",
    "    \"\"\"\n",
    "    Takes a string as input and removes the \"$\" character and then transforms it to an\n",
    "    integer. If errors occur (e.g., string is empty), assigns a value of zero.\n",
    "    \n",
    "    Args:\n",
    "        value: Input string to be normalized.\n",
    "    \n",
    "    Returns:\n",
    "        int_value: Value as integer and without \"$\" character.\n",
    "    \"\"\"\n",
    "    \n",
    "    clean_value = re.sub(r\"[\\D]\", \"\", value)  # the \\D will match strings that don't contain digits\n",
    "    try:\n",
    "        int_value = int(clean_value)\n",
    "    except:\n",
    "        int_value = 0\n",
    "    return int_value\n",
    "\n",
    "# Apply the normalization function to the \"Value\" column\n",
    "jeopardy[\"clean_value\"] = jeopardy[\"Value\"].apply(norm_value)\n",
    "\n",
    "# Apply the pd.to_datetime function to the \"Air Date\" column\n",
    "jeopardy[\"Air Date\"] = pd.to_datetime(jeopardy[\"Air Date\"])\n",
    "\n",
    "# Display results\n",
    "print(jeopardy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to figure out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "\n",
    "* How often the answer can be used for a question.\n",
    "* How often questions are repeated.\n",
    "\n",
    "We can answer the first question by seeing how many times words in the answer also occur in the question. SImilarly, we can answer the second question by seeing how often complex words (> 6 characters) reoccur.\n",
    "\n",
    "Let's work on the first question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How often the answer can be used for a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean percentage of words in the answer that also occur in the question is 5.9%.\n"
     ]
    }
   ],
   "source": [
    "def match_words(row):\n",
    "    \"\"\"\n",
    "    Takes a row as input, and returns the proportion of words in the \"clean_answer\" column\n",
    "    that are also in the \"clean_question\" column.\n",
    "    \n",
    "    Args:\n",
    "        row: row of the dataframe to work with.\n",
    "    \n",
    "    Returns:\n",
    "        p_answer_in_question : proportion of words in the \"clean_answer\" column that \n",
    "        are also in the \"clean_question\" column.\n",
    "    \"\"\"\n",
    "    \n",
    "    split_answer = row[\"clean_answer\"].split()\n",
    "    split_question = row[\"clean_question\"].split()\n",
    "    match_count = 0\n",
    "    if \"the\" in split_answer:\n",
    "        split_answer.remove(\"the\")\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    for word in split_answer:\n",
    "        if word in split_question:\n",
    "            match_count += 1\n",
    "    p_answer_in_question = match_count / len(split_answer)\n",
    "    return p_answer_in_question\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "jeopardy[\"answer_in_question\"] = jeopardy.apply(match_words, axis=1)\n",
    "\n",
    "# Calculate the mean value of the new column\n",
    "mean_value = jeopardy[\"answer_in_question\"].mean()\n",
    "\n",
    "# Display the results\n",
    "print(\"The mean percentage of words in the answer that also occur in the question is {}%.\".format(round(mean_value * 100, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the mean percentage of words in the answer which also occur in the question is under 6%, we do not recommend trying to answer a question with words already contained in it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How often questions are repeated\n",
    "\n",
    "Let's say we want to investigate how often new questions are repeats of older ones. We can't completely answer this, because we only have about `10%` of the full Jeopardy question dataset, but we can investigate it at least. We'll only analyze words with six or more characters to filter out words like \"the\" and 'than\", which are commonly used, but don't tell us a lot about a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Show Number   Air Date             Round                  Category  \\\n",
      "1953         6294 2012-01-19  Double Jeopardy!   WEAPONS OF WORLD WAR II   \n",
      "1954         6294 2012-01-19  Double Jeopardy!   ACTING PRESIDENTS ON TV   \n",
      "1942         6294 2012-01-19         Jeopardy!                    INLETS   \n",
      "1943         6294 2012-01-19         Jeopardy!  THE EVOLUTION OF \"M\"USIC   \n",
      "1922         6294 2012-01-19         Jeopardy!           THAT'S BUSINESS   \n",
      "\n",
      "      Value                                           Question  \\\n",
      "1953   $800  Ships in the U.S. Navy's Casablanca class of \"...   \n",
      "1954   $800  Dennis Haysbert & D.B. Woodside as David & Way...   \n",
      "1942  $1000  North Carolina's Albemarle Sound is no deeper ...   \n",
      "1943  $1000  In the 2000s \"Makes Me Wonder\" got this group ...   \n",
      "1922   $400  In 1997 Tyco International moved to this U.K. ...   \n",
      "\n",
      "                 Answer                                     clean_question  \\\n",
      "1953  aircraft carriers  ships in the us navys casablanca class of esco...   \n",
      "1954                 24  dennis haysbert  db woodside as david  wayne p...   \n",
      "1942    the Outer Banks  north carolinas albemarle sound is no deeper t...   \n",
      "1943           Maroon 5  in the 2000s makes me wonder got this group no...   \n",
      "1922            Bermuda  in 1997 tyco international moved to this uk te...   \n",
      "\n",
      "           clean_answer  clean_value  answer_in_question  question_overlap  \n",
      "1953  aircraft carriers          800                 0.0          1.000000  \n",
      "1954                 24          800                 0.0          0.600000  \n",
      "1942    the outer banks         1000                 0.0          0.833333  \n",
      "1943           maroon 5         1000                 0.0          1.000000  \n",
      "1922            bermuda          400                 0.0          1.000000  \n",
      "\n",
      "The mean proportion of questions that have been already used is 68.9%.\n"
     ]
    }
   ],
   "source": [
    "# Initiate empty list and set that are to be used later\n",
    "question_overlap = []\n",
    "terms_used = set()\n",
    "\n",
    "# Sort the dataframe by the \"Air Date\" column in ascending order\n",
    "jeopardy = jeopardy.sort_values(by = \"Air Date\")\n",
    "\n",
    "# For each row of the dataframe, split the \"clean_question\" column, keep words with >5 characters,\n",
    "# and check if each word has been previously used - \"terms_used\" set. Calculate the proportion of\n",
    "# used words per row.\n",
    "for index, row in jeopardy.iterrows():\n",
    "    split_question = row[\"clean_question\"].split()\n",
    "    split_question = [q for q in split_question if len(q) > 5]\n",
    "    match_count = 0\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "        terms_used.add(word)\n",
    "    if len(split_question) > 0:\n",
    "        match_count /= len(split_question)\n",
    "    question_overlap.append(match_count)\n",
    "\n",
    "# Assign the list of proportions calculated above to the `question_overlap`\" column.\n",
    "jeopardy[\"question_overlap\"] = question_overlap\n",
    "\n",
    "# Convert the column to float type\n",
    "jeopardy[\"question_overlap\"] = jeopardy[\"question_overlap\"].astype(float)\n",
    "\n",
    "# Calculate mean proportion of the new column\n",
    "mean_val = jeopardy[\"question_overlap\"].mean()\n",
    "\n",
    "# Display results from the bottom (more chances to get proportions different from zero, as the words have been previously used)\n",
    "print(jeopardy.tail())\n",
    "\n",
    "# Display mean proportion of used words\n",
    "print()\n",
    "print(\"The mean proportion of questions that have been already used is {}%.\".format(round(mean_val * 100, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Low Value vs High Value Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is about a `70%` overlap between terms in new questions and terms in old questions. This only looks at a small set of questions, and it doesn't look at phrases — it looks at single terms. This makes it relatively insignificant, but it does mean that it's worth looking more into the recycling of questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say you only want to study questions that pertain to high value questions instead of low value questions. This will help you earn more money when you're on Jeopardy.\n",
    "\n",
    "You can actually figure out which terms correspond to high-value questions using a chi-squared test. You'll first need to narrow down the questions into two categories:\n",
    "\n",
    "* Low value -- Any row where Value is less than `800`.\n",
    "* High value -- Any row where Value is greater than `800`.\n",
    "\n",
    "You'll then be able to loop through each of the terms in `terms_used` and find the words with the biggest differences in usage between high and low value questions, by selecting the words with the highest associated chi-squared values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The random sample of terms is:\n",
      "\n",
      "dreamily\n",
      "hardings\n",
      "carolyn\n",
      "safinas\n",
      "liquefy\n",
      "trifle\n",
      "officially\n",
      "genome\n",
      "goulet\n",
      "competing\n",
      "\n",
      "The observed high and low values counts are:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 0),\n",
       " (1, 0),\n",
       " (0, 2),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (9, 12),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a column with value 1 for \"clean_value\" values greater than 800, and 0 otherwise\n",
    "jeopardy[\"high_value\"] = jeopardy[\"clean_value\"].apply(lambda x: 1 if x >= 800 else 0)\n",
    "\n",
    "# Create the function to determine high and low counts for words\n",
    "def high_low_counts(word):\n",
    "    \"\"\"\n",
    "    Takes a word as input, and returns the number of times it appeared in \n",
    "    high value and low value questions.\n",
    "    \n",
    "    Args:\n",
    "        word: Word to be searched in previous questions.\n",
    "    \n",
    "    Returns:\n",
    "        high_count: Number of times the word appeared in high value questions.\n",
    "        low_count: Number of times the word appeared in low value questions.\n",
    "    \"\"\"\n",
    "    \n",
    "    low_count = 0\n",
    "    high_count= 0\n",
    "    for index, row in jeopardy.iterrows():\n",
    "        split_question = row[\"clean_question\"].split()\n",
    "        if word in split_question:\n",
    "            if row[\"high_value\"] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count\n",
    "\n",
    "# Take a random sample from the terms_used list to test the function\n",
    "random.seed(1)\n",
    "comparison_terms = random.sample(list(terms_used), 10)\n",
    "print(\"The random sample of terms is:\")\n",
    "print()\n",
    "print('\\n'.join(comparison_terms))\n",
    "\n",
    "# Apply the function in the sample, and display the results\n",
    "observed_expected = []\n",
    "for word in comparison_terms:\n",
    "    observed_expected.append(high_low_counts(word))\n",
    "print()\n",
    "print(\"The observed high and low values counts are:\")\n",
    "print()\n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Analysis\n",
    "\n",
    "Now that we've found the observed counts for a few terms, we can compute the expected counts and the chi-squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.295042460408538, 0.25512076479610835],\n",
       " [1.295042460408538, 0.25512076479610835],\n",
       " [1.5443509082853344, 0.21397134128528295],\n",
       " [0.7721754541426672, 0.3795448984353682],\n",
       " [0.03360895727560264, 0.8545410902144307],\n",
       " [1.295042460408538, 0.25512076479610835],\n",
       " [0.004366889982650542, 0.9473121844751238],\n",
       " [0.7721754541426672, 0.3795448984353682],\n",
       " [0.7721754541426672, 0.3795448984353682],\n",
       " [0.7721754541426672, 0.3795448984353682]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_value_count = jeopardy[\"high_value\"].value_counts()[1]\n",
    "low_value_count = jeopardy[\"high_value\"].value_counts()[0]\n",
    "chi_squared = []\n",
    "\n",
    "for list in observed_expected:\n",
    "    total = sum(list)\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    expected_high = high_value_count * total_prop\n",
    "    expected_low = low_value_count * total_prop\n",
    "    chisq_value, pvalue_gender_income = chisquare(np.array(list), np.array([expected_high, expected_low]))\n",
    "    chi_squared.append([chisq_value, pvalue_gender_income])\n",
    "\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Low value count  High value count  Chi Square   p value\n",
      "dreamily                  1                 0    1.295042  0.255121\n",
      "hardings                  1                 0    1.295042  0.255121\n",
      "carolyn                   0                 2    1.544351  0.213971\n",
      "safinas                   0                 1    0.772175  0.379545\n",
      "liquefy                   1                 1    0.033609  0.854541\n",
      "trifle                    1                 0    1.295042  0.255121\n",
      "officially                9                12    0.004367  0.947312\n",
      "genome                    0                 1    0.772175  0.379545\n",
      "goulet                    0                 1    0.772175  0.379545\n",
      "competing                 0                 1    0.772175  0.379545\n"
     ]
    }
   ],
   "source": [
    "# Transform the observed_expected values to dataframe\n",
    "results = pd.DataFrame(observed_expected, index = comparison_terms, columns = [\"Low value count\", \"High value count\"])\n",
    "\n",
    "# Add the chi square and p values as columns\n",
    "results[\"Chi\"] = chi_squared\n",
    "results[[\"Chi Square\", \"p value\"]] = pd.DataFrame(results.Chi.tolist(), index= results.index)\n",
    "results.drop(\"Chi\", axis=1, inplace = True)\n",
    "\n",
    "# Display the results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above show that, from the sample words that we've used our function with, there's no statistically significant difference regarding whether they appear more on high value or low value questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, a dataset of Jeopardy questions has been used to figure out some patterns in the questions that could help to win. After exploring we figured out that:\n",
    "\n",
    "* On average about 6% of the words of answers are found in the questions. So the chance of deducing the answer from the question is quite low.\n",
    "* About 69% of the complex words in questions are repeated so studying the past questions can be really helpful to win.\n",
    "* There's no difference on the sample of words that we analyzed to be on high value or low value questions.\n",
    "\n",
    "The next step can be finding the questions with the high value containing these words. These questions can be recommended to study and win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
